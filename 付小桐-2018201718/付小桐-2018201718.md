# NLP课程作业——BERT-CNN虚假评论分类器

## 一、背景介绍

​	在线商品评论是消费者通过网络平台，对某种商品或服务进行评价的信息，是网络口碑的一种形式。在网购情境下，人们无法看到商品实物，只能通过线上交流的方式获取信息，在线评论就是最为重要的信息源之一。据中国互联网信息中心2016 年的《中国网络购物市场研究报告》，高达77.5%的消费者购买时首要参考商品的在线评论。评论的数量、质量和效价对消费者的购买意愿都有着显著的影响，在线评论在消费者购买行为中扮演着越来越重要的角色。

​	随着评论的重要性与日俱增，评论区已然成为商品的“第二张脸”。下图展示的三种评论，想必常常网上购物的人都不会陌生：

- 第一张为真实评论，它们往往语言简洁，评价中肯；

- 第二张图则是明显的虚假评论，充斥着表情符号与泛泛的赞美，并具有引导购买的倾向（“喜欢的亲不要犹豫了”）；

- 第三张图所展现的评论具有一定迷惑性，但仔细阅读文字会发现，文字通篇是对于店铺和商品的吹捧，词句之间基本没有逻辑联系，并在最后一句落到”推荐购买“的重点。

<img src="https://github.com/DaybreakHajime/nlp21projects/blob/main/%E4%BB%98%E5%B0%8F%E6%A1%90-2018201718/extra/images/true.png" width="300px"/><img src="https://github.com/DaybreakHajime/nlp21projects/blob/main/%E4%BB%98%E5%B0%8F%E6%A1%90-2018201718/extra/images/false1.png" width="300px"/><img src="https://github.com/DaybreakHajime/nlp21projects/blob/main/%E4%BB%98%E5%B0%8F%E6%A1%90-2018201718/extra/images/false2.png" width="300px"/>


​	类似的虚假评论不能够为消费者提供真实反馈，反而渗透进网购世界信息库，利用其绝佳的伪装混迹于评论群里，暗中影响着消费者对产品的判断，并以最终影响消费者购买行为作为目标。这些虚假评论借助海量的网购评论信息隐藏自己，使得人工筛查成本过于高昂，故虚假评论的识别具有重要意义。

## 二、 数据获取及预处理

### 1. 原始数据准备

​	本模型使用的数据爬取自“笔记本电脑”搜索页的京东评论，共计约3000条，并进行人工标注分类。其分类标准主要有以下几条：

- 是否有逻辑关系
- 是否与本商品有关
- 是否罗列商品属性
- 是否有过多的表情和特殊符号
- 是否落点于推荐购买
- 是否为复制粘贴他人评论
- 是否过多使用“宝贝”、“亲们”等词语

​	最终标记出449条虚假评论，2532条真实评论，展示数据如下：

```python
#读取数据
alldata = pd.read_excel('labeled评论数据.xlsx')
#提取虚假评论数据
all_false=alldata[alldata['标签']==1]
#设置index
all_false.index=range(0,len(all_false))
#提取文本内容
false_text=all_false['评价内容']
#提取真实评论数据
all_true=alldata[alldata['标签']==0]
#设置index
all_true.index=range(len(all_false),len(alldata))
#提取文本内容
true_text=all_true['评价内容']
#将真假文本内容按顺序连接
sentences = false_text.append(true_text)
#展示虚假评论数据
all_false.loc[1:5]
```



<img src="https://github.com/DaybreakHajime/nlp21projects/blob/main/%E4%BB%98%E5%B0%8F%E6%A1%90-2018201718/extra/images/data.png" alt="image-20211201104230080" style="zoom:80%;" />

### 2. 数据增强	

​	由于数据存在明显的不平衡，在训练前我们使用常用文本数据增强方式，回译（Back Translation）的方法进行了增强。通过Google翻译将虚假评论文本翻译为英文再翻译回中文，以此手动增加了虚假评论数量，最终获得了3431条数据，其中898条虚假评论。具体操作效果如下表：

| 原始评论                                                     | 翻译评论                                                     | 回译评论                                                     |
| ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 外星人（ALIENWARE）全新x15R1笔记本电脑15.6英寸11代酷睿30显卡独显电竞吃鸡游戏 1778:11代i7/32G/3070/2K屏 官方标配。物超所值，商品设计完美，外观也很高大上，让人爱不释手。客服更是热情的没话说，这次购物很满意 | Alienware brand new x15R1 laptop 15.6-inch 11-generation Core 30 graphics card alone shows the e-sports chicken game 1778: the 11-generation i7/32G/3070/2K screen is the official standard. The value for money, the perfect product design, and the appearance is also very tall. The customer service is more enthusiastic, nothing to say, I am very satisfied with this shopping | Alienware全新x15R1笔记本电脑15.6英寸11代酷睿30显卡独显电竞吃鸡1778：11代i7/32G/3070/2K屏为官方标配。物超所值，完美的产品设计，外观也是非常的高大上。客服比较热情，没什么好说的，这次购物我很满意 |

### 3. 数据预处理

​	预处理部分，我们主要进行了tokenize、encode、ellipsis/padding、mask等步骤，具体操作步骤如下图：

![image-20211124140900279](https://github.com/DaybreakHajime/nlp21projects/blob/main/%E4%BB%98%E5%B0%8F%E6%A1%90-2018201718/extra/images/bert.png)

​	最终将文本处理为两部分：1. 文本编码；2. mask，作为Bert的原始输入，处理效果如下所示：

```python
#查看encode mask后效果
split_seed=156
from sklearn.model_selection import train_test_split
train_inputs, test_inputs, train_labels, test_labels = train_test_split(input_tokens, total_targets, random_state=666, test_size=0.2)
train_masks, test_masks, _, _ = train_test_split(attention_tokens, input_tokens, random_state=666, test_size=0.2)
print(train_inputs.shape, test_inputs.shape)      #torch.Size([2744, 132]) torch.Size([686, 132])
print(train_masks.shape)                          #torch.Size([2744, 132])和train_inputs形状一样

print(train_inputs[0])
#tensor([ 101, 4381,  749, 1126, 1921, 4294, 1765, 3341, 6397,  817, 8024, 7032,
#        2247, 6574, 2697, 2523, 3472, 8024, 7241, 4669, 3145, 1140, 2697, 2523,
#        3300, 1213, 2428, 8024, 6820, 3300, 1392, 4905, 7582, 5682, 7241, 4669,
#        4128, 8024, 2242, 2391, 2523, 5301, 5594, 8024, 7770, 5682, 1818, 3766,
#        6413, 6432, 8024, 1215, 1062, 3952, 2767, 4312, 7604,  676, 4905, 6444,
#        5688, 3563, 2466,  671, 7241, 6760, 2940, 2523, 3175,  912, 8024, 3353,
#        5636, 2487, 1107, 2458, 1423, 1400, 4746, 7313, 2218, 5543, 1762, 4764,
#        3198, 7313, 1079, 7360,  856, 8024, 5011, 6381, 3315, 3946, 2428, 2523,
#        3472, 8024, 5401,  704,  679, 6639, 4638, 3221, 5330, 5661,  679, 5314,
#        1213, 8024, 4510, 3737, 1372, 5543, 5335, 2898,  697,  702, 2207, 3198,
#        8024, 3300,  671, 6432,  671,  511,  102,    0,    0,    0,    0,    0])
print(train_masks[0])
#tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
#        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
#        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
#        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
#        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
#        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
#        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
#        1., 0., 0., 0., 0., 0.])
```



## 三、模型训练

​	本部分我们将使用：1. BERT直接分类模型； 2. BERT-CNN分类模型，分别对评论文本进行分类，并对比他们的分类效果。其模型结构如下图所示：

![未命名文件 (1)](https://github.com/DaybreakHajime/nlp21projects/blob/main/%E4%BB%98%E5%B0%8F%E6%A1%90-2018201718/extra/images/structure.jpg)

​	根据反复尝试，我们设置环境变量如下：

```python
#设置模型参数
SEED = 1508
BATCH_SIZE = 30
LEARNING_RATE = 2e-5
WEIGHT_DECAY = 1e-2
EPSILON = 1e-8
random.seed(SEED)
np.random.seed(SEED)
torch.manual_seed(SEED)
torch.cuda.manual_seed_all(SEED)
```

​	同时设置epoch为15，并使用学习率scheduler对optimizer进行优化。

```python
#设置epoch
epochs = 15
#training steps 的数量: [number of batches] x [number of epochs]. 
total_steps = len(train_dataloader) * epochs

# 设计学习率scheduler.
scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps = total_steps)
```

### 1. 模型一：BERT直接分类

​	对于模型一，我们直接使用BertForSequenceClassification.from_pretrained函数，加载哈工大BERT中文预训练模型RoBERTa-wwm-ext，设置输出分类为2，最终结果如下图所示：

```python
model = BertForSequenceClassification.from_pretrained("hfl/chinese-roberta-wwm-ext", num_labels = 2)     #num_labels表示2个分类，好评和差评


device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

with torch.no_grad():
     model.to(device)
```

![image-20211222192346814](https://github.com/DaybreakHajime/nlp21projects/blob/main/%E4%BB%98%E5%B0%8F%E6%A1%90-2018201718/extra/images/model1.png)

- 测试集准确率稳定在0.88左右，召回率稳定在0.74左右
- 出现了一定过拟合现象

### 2. 模型二： BERT-CNN分类

​	对于模型二，我们在BERT输出变量的基础上运用CNN网络，添加了粒度分别为3、4、5的卷积以提取特征，经过激活、最大池化后通过全连接层至两分类。模型最终结果如下：

```python
#定义模型
class Model(nn.Module):

    def __init__(self):
        super(Model, self).__init__()
        #引入bert
        self.bert = BertModel.from_pretrained("hfl/chinese-roberta-wwm-ext", output_hidden_states=True)
        for param in self.bert.parameters():
            param.requires_grad = True
        #定义CNN参数，分别使用3、4、5提取不同粒度的特征
        self.conv1 = nn.Conv2d(1, 100, 3, padding=[2,0])
        self.conv2 = nn.Conv2d(1, 100, 4, padding=[3,0])
        self.conv3 = nn.Conv2d(1, 100, 5, padding=[4,0])
        self.dropout=nn.Dropout(p=0.5)
        self.fc = nn.Linear(100*598, 2)

    def forward(self, b_input_ids,b_input_mask):
        bert_out=self.bert(b_input_ids, attention_mask=b_input_mask)
        #拿出BERT结果
        out=bert_out['pooler_output']
        out=out.unsqueeze(1)
        out=out.unsqueeze(1)
        #进行卷积并激活
        x = [F.relu(self.conv1(out)), F.relu(self.conv2(out)), F.relu(self.conv3(out))]
        # 进行池化
        x = [F.max_pool2d(i, i.size(2)).squeeze(2) for i in x]
        x=[i.squeeze(0) for i in x]
        #连接各层
        x = torch.cat(x, 2)
        #添加dropout
        x = self.dropout(x)
        x=x.view(-1,100*598)
        #全连接输出概率
        logit = self.fc(x)
        
        return logit
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = Model().to(device)
```

![自定义3](https://github.com/DaybreakHajime/nlp21projects/blob/main/%E4%BB%98%E5%B0%8F%E6%A1%90-2018201718/extra/images/model2.png)

- 测试集准确率稳定在0.86左右，召回率稳定在0.81左右
- 同样出现了过拟合现象

## 四、模型评估和应用

​	下面我们将自定义的BERT-CNN模型与BERT的分类效果进行对比，其测试集的准确率、召回率对比如下图所示：


![对比2](https://github.com/DaybreakHajime/nlp21projects/blob/main/%E4%BB%98%E5%B0%8F%E6%A1%90-2018201718/extra/images/contrast.png)

- 准确率方面，BERT直接分类略高于BERT-CNN模型
- 召回率方面，BERT-CNN明显高于BERT直接分类

​	综合来看，BERT-CNN模型准确率略低，但召回率明显高于BERT直接分类。一方面，这说明了CNN网络确实能够较为有效的提取特征，在我们以虚假评论为关注重点时表现效果更好；另一方面，BERT-CNN模型准确率不够理想可能是由于模型参数过多，而我们的数据集仅有3000条左右数据，自由度过低，此时参数较少的BERT直接分类模型反而效果更佳。

​	下面我们实际对模型二进行应用，输入一条随机评论判断真假，效果如下：

```python
#模型应用效果
label =predict('外星人（ALIENWARE）全新x15R1笔记本电脑15.6英寸11代酷睿30显卡独显电竞吃鸡游戏 1778:11代i7/32G/3070/2K屏 官方标配。物超所值，商品设计完美，外观也很高大上，让人爱不释手。客服更是热情的没话说，这次购物很满意')
print('label:',label.item())
#tensor([[-3.9373,  4.3088]], device='cuda:0', grad_fn=<AddmmBackward>)
#label: 1
```

​	对于这种类似罗列商品属性的评论，模型判断结果准确，这也符合我们的预期。
