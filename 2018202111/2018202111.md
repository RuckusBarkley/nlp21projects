# Project (Chatbot)

## 1. Description

+ Build a chatbot supports both Chinese and English.

## 2. Dataset

+ [Cornell Movie-Dialogs Corpus](https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html)
+ LCCC: [A Large-scale Chinese Short-Text Conversation Dataset and Chinese pre-training dialog models](https://github.com/thu-coai/CDial-GPT)
+ ...

## 3. Problems

+ How to understand the input sentence rather than just discrete words?

  + use Recurrent Neural Networks ✅

+ How to represent a sentence?

  + use a vector of word index ✅

+ Further optimization of the chatbot?

  + use more data to train ✅

  + use better representation of sentence (word index -> word embedding) ✅

  + use attention mechanisms to improve performance on long sequence ✅

    ![attn2](https://pytorch.org/tutorials/_images/attn2.png)

## 4. Model

+ Recurrent Neural Networks (GRU and LSTM)

  + Example: Bidirectional RNN

  ![rnn bidir](https://pytorch.org/tutorials/_images/RNN-bidirectional.png)

+ Seq2Seq Model (a network with Encoder and Decoder)

![seq2seq model](https://zh.d2l.ai/_images/seq2seq.svg)

![model](https://pytorch.org/tutorials/_images/seq2seq_ts.png)

+ Loss function: cross entropy loss function

## 5. Progress

+ Support Chinese Chatting ✅
+ Support English Chatting ✅

## 6. References

[1] Cho, K., Van Merriënboer, B., Gulcehre, C., Bahdanau, D., Bougares, F., Schwenk, H., & Bengio, Y. (2014). Learning phrase representations using RNN encoder-decoder for statistical machine translation. arXiv preprint arXiv:1406.1078.

[2] Sutskever, I., Vinyals, O., & Le, Q. V. (2014). Sequence to sequence learning with neural networks. In Advances in neural information processing systems (pp. 3104-3112).

[3] Luong, M. T., Pham, H., & Manning, C. D. (2015). Effective approaches to attention-based neural machine translation. *arXiv preprint arXiv:1508.04025*.
