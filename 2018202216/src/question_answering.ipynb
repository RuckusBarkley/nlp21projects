{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f000b77-28c1-4dac-a6c3-d1b86c41c740",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
    "from transformers import default_data_collator\n",
    "from datasets import load_dataset, load_metric\n",
    "import numpy as np\n",
    "from datasets import ClassLabel, Sequence\n",
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "import collections\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b61d7985-03a7-4aea-a8b4-0676eeed2ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.14.1\n"
     ]
    }
   ],
   "source": [
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2d3889-13de-4788-bd55-240e675e6ef7",
   "metadata": {},
   "source": [
    "数据导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74064f2c-d07e-4e8a-a574-a4bbc5fe7775",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/squad/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453 (last modified on Wed Dec 22 09:23:34 2021) since it couldn't be found locally at squad., or remotely on the Hugging Face Hub.\n",
      "Reusing dataset squad (/root/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e489f60ec8cf4ec5ac2091a7e78e9d9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datasets = load_dataset(\"squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20e180ce-cd29-41ea-bb3c-65bc024364b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_random_elements(dataset, num_examples=12):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "    \n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "        elif isinstance(typ, Sequence) and isinstance(typ.feature, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda x: [typ.feature.names[i] for i in x])\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1af9948d-4c0d-4314-a2be-b1056b3f827a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5726bee5f1498d1400e8e9f1</td>\n",
       "      <td>Nigeria</td>\n",
       "      <td>The name Nigeria was taken from the Niger River running through the country. This name was allegedly coined in the late 19th century by British journalist Flora Shaw, she was inspired by the name of the river, in preference to terms such as \"Central Sudan\". The origin of the name ''Nigeria'' came from the name of the Niger River. The word ( Niger )  is an alteration of the Tuareg name egerew n-igerewen used by inhabitants along the middle reaches of the river around Timbuktu prior to 19th-century European colonialism. Egerew n-igerewen means River of the Rivers.</td>\n",
       "      <td>Who came up with the name Nigeria in the 19th century?</td>\n",
       "      <td>{'text': ['Flora Shaw'], 'answer_start': [155]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56f6e8fb3d8e2e1400e372b5</td>\n",
       "      <td>Slavs</td>\n",
       "      <td>Slavs are the largest Indo-European ethno-linguistic group in Europe. They inhabit Central Europe, Eastern Europe, Southeast Europe, North Asia and Central Asia. Slavs speak Indo-European Slavic languages and share, to varying degrees, some cultural traits and historical backgrounds. From the early 6th century they spread to inhabit most of Central and Eastern Europe and Southeast Europe, whilst Slavic mercenaries fighting for the Byzantines and Arabs settled Asia Minor and even as far as Syria. The East Slavs colonised Siberia and Central Asia.[better source needed] Presently over half of Europe's territory is inhabited by Slavic-speaking communities, but every Slavic ethnicity has emigrated to other continents.</td>\n",
       "      <td>What areas of the world do Slavs inhabit?</td>\n",
       "      <td>{'text': ['They inhabit Central Europe, Eastern Europe, Southeast Europe, North Asia and Central Asia.'], 'answer_start': [70]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>572ff590947a6a140053ce7b</td>\n",
       "      <td>Premier_League</td>\n",
       "      <td>The Golden Boot is awarded to the top Premier League scorer at the end of each season. Former Blackburn Rovers and Newcastle United striker Alan Shearer holds the record for most Premier League goals with 260. Twenty-four players have reached the 100-goal mark. Since the first Premier League season in 1992–93, 14 different players from 10 different clubs have won or shared the top scorers title. Thierry Henry won his fourth overall scoring title by scoring 27 goals in the 2005–06 season. Andrew Cole and Alan Shearer hold the record for most goals in a season (34) – for Newcastle and Blackburn respectively. Ryan Giggs of Manchester United holds the record for scoring goals in consecutive seasons, having scored in the first 21 seasons of the league.</td>\n",
       "      <td>Who has the record for most goals in the Premier League?</td>\n",
       "      <td>{'text': ['Newcastle United striker Alan Shearer holds the record for most Premier League goals with 260'], 'answer_start': [115]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5728d4373acd2414000dff97</td>\n",
       "      <td>Detroit</td>\n",
       "      <td>The city is governed pursuant to the Home Rule Charter of the City of Detroit. The city government is run by a mayor and a nine-member city council and clerk elected on an at-large nonpartisan ballot. Since voters approved the city's charter in 1974, Detroit has had a \"strong mayoral\" system, with the mayor approving departmental appointments. The council approves budgets but the mayor is not obligated to adhere to any earmarking. City ordinances and substantially large contracts must be approved by the council. The Detroit City Code is the codification of Detroit's local ordinances.</td>\n",
       "      <td>How many people are on the city council?</td>\n",
       "      <td>{'text': ['nine'], 'answer_start': [123]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>572b881ebe1ee31400cb8412</td>\n",
       "      <td>New_Haven,_Connecticut</td>\n",
       "      <td>New Haven is served by the daily New Haven Register, the weekly \"alternative\" New Haven Advocate (which is run by Tribune, the corporation owning the Hartford Courant), the online daily New Haven Independent, and the monthly Grand News Community Newspaper. Downtown New Haven is covered by an in-depth civic news forum, Design New Haven. The Register also backs PLAY magazine, a weekly entertainment publication. The city is also served by several student-run papers, including the Yale Daily News, the weekly Yale Herald and a humor tabloid, Rumpus Magazine. WTNH Channel 8, the ABC affiliate for Connecticut, WCTX Channel 59, the MyNetworkTV affiliate for the state, and Connecticut Public Television station WEDY channel 65, a PBS affiliate, broadcast from New Haven. All New York City news and sports team stations broadcast to New Haven County.</td>\n",
       "      <td>What is the name of the tabloid that is run by mainly college students?</td>\n",
       "      <td>{'text': ['Rumpus Magazine'], 'answer_start': [543]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>56fa3d788f12f319006300fe</td>\n",
       "      <td>Wood</td>\n",
       "      <td>Age, diameter, height, radial growth, geographical location, site and growing conditions, silvicultural treatment, and seed source, all to some degree influence wood density. Variation is to be expected. Within an individual tree, the variation in wood density is often as great as or even greater than that between different trees (Timell 1986). Variation of specific gravity within the bole of a tree can occur in either the horizontal or vertical direction. :)</td>\n",
       "      <td>What specific type of growth has an effect on the density of wood?</td>\n",
       "      <td>{'text': ['radial'], 'answer_start': [23]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>56de86914396321400ee29fb</td>\n",
       "      <td>BBC_Television</td>\n",
       "      <td>As a division within the BBC, Television was formerly known as BBC Vision for a few years in the early 21st century, until its name reverted to Television in 2013. It is responsible for the commissioning, producing, scheduling and broadcasting of all programming on the BBC's television channels, and is led by Danny Cohen.</td>\n",
       "      <td>What are the four responsibilities of BBC Television?</td>\n",
       "      <td>{'text': ['commissioning, producing, scheduling and broadcasting'], 'answer_start': [190]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5726c4aaf1498d1400e8eab6</td>\n",
       "      <td>Cubism</td>\n",
       "      <td>In contrast, the Salon Cubists built their reputation primarily by exhibiting regularly at the Salon d'Automne and the Salon des Indépendants, both major non-academic Salons in Paris. They were inevitably more aware of public response and the need to communicate. Already in 1910 a group began to form which included Metzinger, Gleizes, Delaunay and Léger. They met regularly at Henri le Fauconnier's studio near the Boulevard de Montparnasse. These soirées often included writers such as Guillaume Apollinaire and André Salmon. Together with other young artists, the group wanted to emphasise a research into form, in opposition to the Neo-Impressionist emphasis on color.</td>\n",
       "      <td>What did the group meeting at Fauconnier's studio want to focus on?</td>\n",
       "      <td>{'text': ['research into form, in opposition to the Neo-Impressionist emphasis on color.'], 'answer_start': [596]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>570cf3e5fed7b91900d45b68</td>\n",
       "      <td>Macintosh</td>\n",
       "      <td>Statistics from late 2003 indicate that Apple had 2.06 percent of the desktop share in the United States that had increased to 2.88 percent by Q4 2004. As of October 2006, research firms IDC and Gartner reported that Apple's market share in the U.S. had increased to about 6 percent. Figures from December 2006, showing a market share around 6 percent (IDC) and 6.1 percent (Gartner) are based on a more than 30 percent increase in unit sale from 2005 to 2006. The installed base of Mac computers is hard to determine, with numbers ranging from 5% (estimated in 2009) to 16% (estimated in 2005).</td>\n",
       "      <td>Who are IDC and Gartner?</td>\n",
       "      <td>{'text': ['research firms'], 'answer_start': [172]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5733b425d058e614000b60bf</td>\n",
       "      <td>Anthropology</td>\n",
       "      <td>One of the central problems in the anthropology of art concerns the universality of 'art' as a cultural phenomenon. Several anthropologists have noted that the Western categories of 'painting', 'sculpture', or 'literature', conceived as independent artistic activities, do not exist, or exist in a significantly different form, in most non-Western contexts. To surmount this difficulty, anthropologists of art have focused on formal features in objects which, without exclusively being 'artistic', have certain evident 'aesthetic' qualities. Boas' Primitive Art, Claude Lévi-Strauss' The Way of the Masks (1982) or Geertz's 'Art as Cultural System' (1983) are some examples in this trend to transform the anthropology of 'art' into an anthropology of culturally specific 'aesthetics'.</td>\n",
       "      <td>When was Art as Cultural System penned?</td>\n",
       "      <td>{'text': ['1983'], 'answer_start': [650]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>572fc6fbb2c2fd1400568451</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>Hyderabad sits at the junction of three National Highways linking it to six other states: NH-7 runs 2,369 km (1,472 mi) from Varanasi, Uttar Pradesh, in the north to Kanyakumari, Tamil Nadu, in the south; NH-9, runs 841 km (523 mi) east-west between Machilipatnam, Andhra Pradesh, and Pune, Maharashtra; and the 280 km (174 mi) NH-163 links Hyderabad to Bhopalpatnam, Chhattisgarh NH-765 links Hyderabad to Srisailam. Five state highways, SH-1, SH-2, SH-4, SH-5 and SH-6, either start from, or pass through, Hyderabad.:58</td>\n",
       "      <td>How many national highways form a junction in Hyderabad?</td>\n",
       "      <td>{'text': ['three'], 'answer_start': [34]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5735a06de853931400426a8f</td>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>The Gorkha Kingdom ended the Malla confederation after the Battle of Kathmandu in 1768. This marked the beginning of the modern era in Kathmandu. The Battle of Kirtipur was the start of the Gorkha conquest of the Kathmandu Valley. Kathmandu was adopted as the capital of the Gorkha empire, and the empire itself was dubbed Nepal. During the early part of this era, Kathmandu maintained its distinctive culture. Buildings with characteristic Nepali architecture, such as the nine-story tower of Basantapur, were built during this era. However, trade declined because of continual war with neighboring nations. Bhimsen Thapa supported France against Great Britain; this led to the development of modern military structures, such as modern barracks in Kathmandu. The nine-storey tower Dharahara was originally built during this era.</td>\n",
       "      <td>What battle inaugurated the conquering of the Kathmandu Valley by the Gorkha?</td>\n",
       "      <td>{'text': ['Kirtipur'], 'answer_start': [160]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(datasets[\"train\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9313e0bf-204d-4815-8c5c-f534a7b56668",
   "metadata": {},
   "source": [
    "数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6fc5141-46ea-4cae-8ded-9774cd2e8884",
   "metadata": {},
   "outputs": [],
   "source": [
    "squad_v2 = False\n",
    "model_checkpoint = \"distilbert-base-uncased\"\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47122116-64de-477a-a5c7-d86098408289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c34abc0feea4c0bb3160e984eb64340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f2ba862256a442f8b1544c98c0f9624",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "875501a1-edc0-44f0-9459-61e220e09083",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_on_right = tokenizer.padding_side == \"right\" #question和context进行拼接 context在右边\n",
    "max_length = 384 # 输入feature的最大长度，question和context拼接之后\n",
    "doc_stride = 128 # 2个切片之间的重合token数量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2171b636-244c-45d3-8707-25699862826d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_train_features(examples):\n",
    "    #对examples进行truncation（截断）和padding（补全）操作\n",
    "    #每一个一个超长文本example会被切片成多个输入，相邻两个输入之间会有交集。\n",
    "    \n",
    "    #清除question里字符间多余的空格\n",
    "    examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n",
    "    \n",
    "    #tokenize文本，并对过长的文本进行截断\n",
    "    tokenized_examples = tokenizer(\n",
    "        examples[\"question\" if pad_on_right else \"context\"],\n",
    "        examples[\"context\" if pad_on_right else \"question\"],\n",
    "        truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
    "        max_length = max_length,\n",
    "        stride = doc_stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,#得到n在切片后context的位置和原始context里位置的对应关系\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    \n",
    "   #overflow_to_sample_mapping参数来映射切片片ID到原始ID，如有2个expamples被切成4片，对应是[0, 0, 1, 1]，前两片对应原来的第一个example\n",
    "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
    "    # offset_mapping也对应4片，映射到原始输入，有助于找到标注在原始输入上的答案的开始和结束位置\n",
    "    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n",
    "    \n",
    "    # 重新标注数据\n",
    "    tokenized_examples[\"start_positions\"] = []\n",
    "    tokenized_examples[\"end_positions\"] = []\n",
    "\n",
    "    for i, offsets in enumerate(offset_mapping):\n",
    "        # 对每一片进行处理\n",
    "        # 将无答案的样本标注到CLS上\n",
    "        input_ids = tokenized_examples[\"input_ids\"][i]\n",
    "        cls_index = input_ids.index(tokenizer.cls_token_id)\n",
    "\n",
    "        # 区分question和context\n",
    "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
    "\n",
    "        # 拿到原始的example 下标.\n",
    "        sample_index = sample_mapping[i]\n",
    "        answers = examples[\"answers\"][sample_index]\n",
    "        # 如果没有答案，则使用CLS所在的位置为答案.\n",
    "        if len(answers[\"answer_start\"]) == 0:\n",
    "            tokenized_examples[\"start_positions\"].append(cls_index)\n",
    "            tokenized_examples[\"end_positions\"].append(cls_index)\n",
    "        else:\n",
    "            # 答案的character级别Start/end位置.\n",
    "            start_char = answers[\"answer_start\"][0]\n",
    "            end_char = start_char + len(answers[\"text\"][0])\n",
    "\n",
    "            # 找到token级别的index start.\n",
    "            token_start_index = 0\n",
    "            while sequence_ids[token_start_index] != (1 if pad_on_right else 0):\n",
    "                token_start_index += 1\n",
    "\n",
    "            # 找到token级别的index end.\n",
    "            token_end_index = len(input_ids) - 1\n",
    "            while sequence_ids[token_end_index] != (1 if pad_on_right else 0):\n",
    "                token_end_index -= 1\n",
    "\n",
    "            # 检测答案是否超出文本长度，超出的话也适用CLS index作为标注.\n",
    "            if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
    "                tokenized_examples[\"start_positions\"].append(cls_index)\n",
    "                tokenized_examples[\"end_positions\"].append(cls_index)\n",
    "            else:\n",
    "                # 如果不超出则找到答案token的start和end位置。.\n",
    "                # Note: we could go after the last offset if the answer is the last word (edge case).\n",
    "                while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
    "                    token_start_index += 1\n",
    "                tokenized_examples[\"start_positions\"].append(token_start_index - 1)\n",
    "                while offsets[token_end_index][1] >= end_char:\n",
    "                    token_end_index -= 1\n",
    "                tokenized_examples[\"end_positions\"].append(token_end_index + 1)\n",
    "\n",
    "    return tokenized_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb6e6f4c-ad34-4011-ae7b-5a56582fbb77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8f7bfef4cab4fac9ae324e77db5eeed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a126068536b5436284d8f1c1c335fd16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = datasets.map(prepare_train_features, batched=True, remove_columns=datasets[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a793e6e-28bb-463f-92fa-532325fab244",
   "metadata": {},
   "source": [
    "微调模型distilbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20d164b4-8f60-4615-85d8-d9363fbfb3e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForQuestionAnswering: ['vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b88dedf-1798-4516-bb40-94cc59096da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3550e84-b259-474f-bbfc-be91940f07cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    f\"test-squad\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate = 2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2cc82a4c-295c-4805-891a-3fdad69113be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据收集器给模型传数据\n",
    "from transformers import default_data_collator\n",
    "data_collator = default_data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b01c5e1b-8466-4f37-8092-04c9f6e252fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#设置模型\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b1530927-cdbb-4ad6-9142-ea68fd159775",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 88524\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2076\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='71' max='2076' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  71/2076 00:53 < 25:50, 1.29 it/s, Epoch 0.10/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='85' max='85' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [85/85 00:42]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_970/4032920361.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/AI/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1323\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1325\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m                 if (\n",
      "\u001b[0;32m~/anaconda3/envs/AI/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   1900\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepspeed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1901\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1902\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1904\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AI/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AI/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f84f95-271b-4d87-ba8b-e61c6333b51a",
   "metadata": {},
   "source": [
    "设置评估方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "147da621-9687-43ab-914b-db965854261d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to test-squad-trained\n",
      "Configuration saved in test-squad-trained/config.json\n",
      "Model weights saved in test-squad-trained/pytorch_model.bin\n",
      "tokenizer config file saved in test-squad-trained/tokenizer_config.json\n",
      "Special tokens file saved in test-squad-trained/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(\"test-squad-trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f6de48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "58dc492f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['loss', 'start_logits', 'end_logits'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "for batch in trainer.get_eval_dataloader():\n",
    "    break\n",
    "batch = {k: v.to(trainer.args.device) for k, v in batch.items()}\n",
    "with torch.no_grad():\n",
    "    output = trainer.model(**batch)\n",
    "output.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1fab2590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 384]), torch.Size([128, 384]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.start_logits.shape, output.end_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b19a4af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 46,  57,  78,  43, 167, 107,  72,  35, 107,  34,  73,  41,  80,  91,\n",
       "         156,  35,  83,  91,  80,  58,  77,  31,  42,  53,  41,  35,  42,  77,\n",
       "          11,  44,  27, 133,  66,  40,  87,  44,  43,  83, 127,  26,  28,  33,\n",
       "          87, 127,  95,  25,  43, 132,  42,  29,  44,  46,  24,  44,  65,  58,\n",
       "          81,  13,  59,  76,  25,  36,  57,  43,  77,  64,  60,  79,  84,  59,\n",
       "          74,  40,  47,  50,  61,  56,  38,  47,  61,  78,  16,  34,  55,  65,\n",
       "          76,  15,  31,  62,  62,  64,  12,  36,  67,  97,   9,  31,  56,  66,\n",
       "          10,  61,  62,  74,  29,  60,  65,  63,  17,  29,  26,  18,  15,  18,\n",
       "          16,  16,  38,  42,  21,  25,  25,  25,  39,  47,  57,  35,  42,  24,\n",
       "          25,  29], device='cuda:0'),\n",
       " tensor([ 47,  58,  81,  44, 171, 110,  75,  37, 110,  36,  76,  42,  83,  94,\n",
       "         158,  35,  83,  94,  83,  60,  80,  31,  43,  54,  42,  35,  43,  80,\n",
       "          13,  45,  28, 133,  66,  41,  89,  45,  44,  85, 127,  27,  30,  34,\n",
       "          89, 127,  97,  26,  44, 132,  43,  30,  45,  47,  25,  45,  65,  59,\n",
       "          81,  14,  60,  72,  25,  36,  58,  43,  77,  65,  60,  75,  84,  60,\n",
       "          70,  40,  47,  50,  62,  56,  38,  47,  62,  74,  16,  36,  56,  68,\n",
       "          80,  15,  33,  65,  65,  67,  12,  38,  70,  97,   9,  33,  57,  69,\n",
       "          10,  64,  65,  78,  31,  63,  68,  66,  19,  29,  26,  20,  16,  20,\n",
       "          18,  18,  38,  42,  21,  39,  39,  52,  41,  50,  60,  39,  44,  51,\n",
       "          25,  56], device='cuda:0'))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#每个feature里的每个token都会有一个logit。预测answer最简单的方法就是选择start的logits里最大的下标最为answer其实位置，end的logits里最大下标作为answer的结束位置。\n",
    "output.start_logits.argmax(dim=-1), output.end_logits.argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e36f029e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_best_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f754bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "start_logits = output.start_logits[0].cpu().numpy()\n",
    "end_logits = output.end_logits[0].cpu().numpy()\n",
    "# 收集最佳的start和end logits的位置:\n",
    "start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "valid_answers = []\n",
    "for start_index in start_indexes:\n",
    "    for end_index in end_indexes:\n",
    "        if start_index <= end_index: # 如果start小于end，那么合理的\n",
    "            valid_answers.append(\n",
    "                {\n",
    "                    \"score\": start_logits[start_index] + end_logits[end_index],\n",
    "                    \"text\": \"\" # 后续需要根据token的下标将答案找出来\n",
    "                }\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f31db7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_validation_features(examples):\n",
    "    # Tokenize our examples with truncation and maybe padding, but keep the overflows using a stride. This results\n",
    "    # in one example possible giving several features when a context is long, each of those features having a\n",
    "    # context that overlaps a bit the context of the previous feature.\n",
    "    tokenized_examples = tokenizer(\n",
    "        examples[\"question\" if pad_on_right else \"context\"],\n",
    "        examples[\"context\" if pad_on_right else \"question\"],\n",
    "        truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
    "        max_length=max_length,\n",
    "        stride=doc_stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    # Since one example might give us several features if it has a long context, we need a map from a feature to\n",
    "    # its corresponding example. This key gives us just that.\n",
    "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
    "\n",
    "    # We keep the example_id that gave us this feature and we will store the offset mappings.\n",
    "    tokenized_examples[\"example_id\"] = []\n",
    "\n",
    "    for i in range(len(tokenized_examples[\"input_ids\"])):\n",
    "        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n",
    "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
    "        context_index = 1 if pad_on_right else 0\n",
    "\n",
    "        # One example can give several spans, this is the index of the example containing this span of text.\n",
    "        sample_index = sample_mapping[i]\n",
    "        tokenized_examples[\"example_id\"].append(examples[\"id\"][sample_index])\n",
    "\n",
    "        # Set to None the offset_mapping that are not part of the context so it's easy to determine if a token\n",
    "        # position is part of the context or not.\n",
    "        tokenized_examples[\"offset_mapping\"][i] = [\n",
    "            (o if sequence_ids[k] == context_index else None)\n",
    "            for k, o in enumerate(tokenized_examples[\"offset_mapping\"][i])\n",
    "        ]\n",
    "\n",
    "    return tokenized_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9656b888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97e7f0647fe24ac5a5bb52dfd564b8fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "validation_features = datasets[\"validation\"].map(\n",
    "    prepare_validation_features,\n",
    "    batched=True,\n",
    "    remove_columns=datasets[\"validation\"].column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "db375543",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `DistilBertForQuestionAnswering.forward` and have been ignored: offset_mapping, example_id.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 10784\n",
      "  Batch size = 128\n"
     ]
    }
   ],
   "source": [
    "raw_predictions = trainer.predict(validation_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ea378982",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_answer_length = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "64e583f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 15.940137, 'text': 'Denver Broncos'},\n",
       " {'score': 14.570858,\n",
       "  'text': 'Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers'},\n",
       " {'score': 12.870857, 'text': 'Carolina Panthers'},\n",
       " {'score': 11.056548, 'text': 'Broncos'},\n",
       " {'score': 11.034536,\n",
       "  'text': 'American Football Conference (AFC) champion Denver Broncos'},\n",
       " {'score': 10.878145, 'text': 'Denver'},\n",
       " {'score': 10.668441,\n",
       "  'text': 'The American Football Conference (AFC) champion Denver Broncos'},\n",
       " {'score': 9.687268,\n",
       "  'text': 'Broncos defeated the National Football Conference (NFC) champion Carolina Panthers'},\n",
       " {'score': 9.6652565,\n",
       "  'text': 'American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers'},\n",
       " {'score': 9.299162,\n",
       "  'text': 'The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers'},\n",
       " {'score': 8.4534645,\n",
       "  'text': 'Denver Broncos defeated the National Football Conference'},\n",
       " {'score': 8.404898,\n",
       "  'text': 'Denver Broncos defeated the National Football Conference (NFC) champion Carolina'},\n",
       " {'score': 7.7891283, 'text': 'Panthers'},\n",
       " {'score': 7.696982, 'text': 'champion Denver Broncos'},\n",
       " {'score': 7.579612,\n",
       "  'text': 'Denver Broncos defeated the National Football Conference (NFC'},\n",
       " {'score': 6.8731318,\n",
       "  'text': 'National Football Conference (NFC) champion Carolina Panthers'},\n",
       " {'score': 6.833566,\n",
       "  'text': 'Denver Broncos defeated the National Football Conference (NFC)'},\n",
       " {'score': 6.704898, 'text': 'Carolina'},\n",
       " {'score': 6.3787546,\n",
       "  'text': 'Denver Broncos defeated the National Football Conference (NFC) champion'},\n",
       " {'score': 6.3551836,\n",
       "  'text': 'Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10'}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_logits = output.start_logits[0].cpu().numpy()\n",
    "end_logits = output.end_logits[0].cpu().numpy()\n",
    "offset_mapping = validation_features[0][\"offset_mapping\"]\n",
    "# The first feature comes from the first example. For the more general case, we will need to be match the example_id to\n",
    "# an example index\n",
    "context = datasets[\"validation\"][0][\"context\"]\n",
    "\n",
    "# Gather the indices the best start/end logits:\n",
    "start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "valid_answers = []\n",
    "for start_index in start_indexes:\n",
    "    for end_index in end_indexes:\n",
    "        # Don't consider out-of-scope answers, either because the indices are out of bounds or correspond\n",
    "        # to part of the input_ids that are not in the context.\n",
    "        if (\n",
    "            start_index >= len(offset_mapping)\n",
    "            or end_index >= len(offset_mapping)\n",
    "            or offset_mapping[start_index] is None\n",
    "            or offset_mapping[end_index] is None\n",
    "        ):\n",
    "            continue\n",
    "        # Don't consider answers with a length that is either < 0 or > max_answer_length.\n",
    "        if end_index < start_index or end_index - start_index + 1 > max_answer_length:\n",
    "            continue\n",
    "        if start_index <= end_index: # We need to refine that test to check the answer is inside the context\n",
    "            start_char = offset_mapping[start_index][0]\n",
    "            end_char = offset_mapping[end_index][1]\n",
    "            valid_answers.append(\n",
    "                {\n",
    "                    \"score\": start_logits[start_index] + end_logits[end_index],\n",
    "                    \"text\": context[start_char: end_char]\n",
    "                }\n",
    "            )\n",
    "\n",
    "valid_answers = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[:n_best_size]\n",
    "valid_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "470c6ef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['Denver Broncos', 'Denver Broncos', 'Denver Broncos'],\n",
       " 'answer_start': [177, 177, 177]}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"validation\"][0][\"answers\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b6829d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "examples = datasets[\"validation\"]\n",
    "features = validation_features\n",
    "\n",
    "example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\n",
    "features_per_example = collections.defaultdict(list)\n",
    "for i, feature in enumerate(features):\n",
    "    features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b304a5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def postprocess_qa_predictions(examples, features, raw_predictions, n_best_size = 20, max_answer_length = 30):\n",
    "    all_start_logits, all_end_logits = raw_predictions\n",
    "    # Build a map example to its corresponding features.\n",
    "    example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\n",
    "    features_per_example = collections.defaultdict(list)\n",
    "    for i, feature in enumerate(features):\n",
    "        features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)\n",
    "\n",
    "    # The dictionaries we have to fill.\n",
    "    predictions = collections.OrderedDict()\n",
    "\n",
    "    # Logging.\n",
    "    print(f\"Post-processing {len(examples)} example predictions split into {len(features)} features.\")\n",
    "\n",
    "    # Let's loop over all the examples!\n",
    "    for example_index, example in enumerate(tqdm(examples)):\n",
    "        # Those are the indices of the features associated to the current example.\n",
    "        feature_indices = features_per_example[example_index]\n",
    "\n",
    "        min_null_score = None # Only used if squad_v2 is True.\n",
    "        valid_answers = []\n",
    "        \n",
    "        context = example[\"context\"]\n",
    "        # Looping through all the features associated to the current example.\n",
    "        for feature_index in feature_indices:\n",
    "            # We grab the predictions of the model for this feature.\n",
    "            start_logits = all_start_logits[feature_index]\n",
    "            end_logits = all_end_logits[feature_index]\n",
    "            # This is what will allow us to map some the positions in our logits to span of texts in the original\n",
    "            # context.\n",
    "            offset_mapping = features[feature_index][\"offset_mapping\"]\n",
    "\n",
    "            # Update minimum null prediction.\n",
    "            cls_index = features[feature_index][\"input_ids\"].index(tokenizer.cls_token_id)\n",
    "            feature_null_score = start_logits[cls_index] + end_logits[cls_index]\n",
    "            if min_null_score is None or min_null_score < feature_null_score:\n",
    "                min_null_score = feature_null_score\n",
    "\n",
    "            # Go through all possibilities for the `n_best_size` greater start and end logits.\n",
    "            start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "            end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "            for start_index in start_indexes:\n",
    "                for end_index in end_indexes:\n",
    "                    # Don't consider out-of-scope answers, either because the indices are out of bounds or correspond\n",
    "                    # to part of the input_ids that are not in the context.\n",
    "                    if (\n",
    "                        start_index >= len(offset_mapping)\n",
    "                        or end_index >= len(offset_mapping)\n",
    "                        or offset_mapping[start_index] is None\n",
    "                        or offset_mapping[end_index] is None\n",
    "                    ):\n",
    "                        continue\n",
    "                    # Don't consider answers with a length that is either < 0 or > max_answer_length.\n",
    "                    if end_index < start_index or end_index - start_index + 1 > max_answer_length:\n",
    "                        continue\n",
    "\n",
    "                    start_char = offset_mapping[start_index][0]\n",
    "                    end_char = offset_mapping[end_index][1]\n",
    "                    valid_answers.append(\n",
    "                        {\n",
    "                            \"score\": start_logits[start_index] + end_logits[end_index],\n",
    "                            \"text\": context[start_char: end_char]\n",
    "                        }\n",
    "                    )\n",
    "        \n",
    "        if len(valid_answers) > 0:\n",
    "            best_answer = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[0]\n",
    "        else:\n",
    "            # In the very rare edge case we have not a single non-null prediction, we create a fake prediction to avoid\n",
    "            # failure.\n",
    "            best_answer = {\"text\": \"\", \"score\": 0.0}\n",
    "        \n",
    "        # Let's pick our final answer: the best one or the null answer (only for squad_v2)\n",
    "        if not squad_v2:\n",
    "            predictions[example[\"id\"]] = best_answer[\"text\"]\n",
    "        else:\n",
    "            answer = best_answer[\"text\"] if best_answer[\"score\"] > min_null_score else \"\"\n",
    "            predictions[example[\"id\"]] = answer\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8652d838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post-processing 10570 example predictions split into 10784 features.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26e10d4d048846c982d586e10a473f21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10570 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_predictions = postprocess_qa_predictions(datasets[\"validation\"], validation_features, raw_predictions.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f8998209",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = load_metric(\"./metrics/squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4544fffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exact_match': 72.37464522232735, 'f1': 81.70197773869668}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_predictions = [{\"id\": k, \"prediction_text\": v} for k, v in final_predictions.items()]\n",
    "references = [{\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in datasets[\"validation\"]]\n",
    "metric.compute(predictions=formatted_predictions, references=references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ea6646",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
